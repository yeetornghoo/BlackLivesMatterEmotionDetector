{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script1.1_Translation_Washington_Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cTJvrhB6WO"
      },
      "source": [
        "# Dataset: Washington DC\n",
        "This Python script is to use Google Colab to check the langague and exclude the tweets which is not english\n",
        "\n",
        "## 1.0 Load Libaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv2WSmWFebLq",
        "outputId": "212036b9-4417-46a4-bc7d-440d2ae1ba0b"
      },
      "source": [
        "!pip install googletrans \n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.6/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.11.21)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: contextvars>=2.1; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from sniffio->httpx==0.13.3->googletrans) (2.4)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.1; python_version < \"3.7\"->sniffio->httpx==0.13.3->googletrans) (0.14)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DTHPg-l1B3"
      },
      "source": [
        "## 2.0 Load Raw Tweet Dataset\n",
        "Dataset load and save as dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XxXKh_qeC96",
        "outputId": "82f4ff5c-a913-462d-964f-cc0be5a9e658"
      },
      "source": [
        "!gdown --id 1GOSvEdRbiBzSQ7xIZkdVjdYenmr5gROs\n",
        "\n",
        "df = pd.read_csv(\"dataset.csv\", sep=\";\")\n",
        "df['tweet_text'] = df['text'].astype(str)\n",
        "print(df.head(5))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GOSvEdRbiBzSQ7xIZkdVjdYenmr5gROs\n",
            "To: /content/dataset.csv\n",
            "15.2MB [00:00, 57.6MB/s]\n",
            "              tweet_id  ...                                         tweet_text\n",
            "0  1245161385392320515  ...  I guess racism made them do it. Can't we all g...\n",
            "1  1245202864001167360  ...  Census 2020 Complete! #Census2020 #BlackLivesM...\n",
            "2  1246215168180269056  ...  I just realized I lived through Y2K, The Iraq ...\n",
            "3  1246318483765374976  ...  We must demand that targeted actions be taken ...\n",
            "4  1246393578710093830  ...  Remembering Dr. King #blacklivesmatter #poorpe...\n",
            "\n",
            "[5 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee_amSZRezhk"
      },
      "source": [
        "def get_sentence_language(sentence):\n",
        "  try:\n",
        "    trs_obj = translator.detect(sentence)\n",
        "    if trs_obj.confidence > 0.95:\n",
        "      return trs_obj.lang\n",
        "  except:\n",
        "    print(\"DataTranslation > Something went wrong\")\n",
        "    return \"UNKNOWN\"\n",
        "  \n",
        "  return \"UNKNOWN\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyeWE7P9eYYI"
      },
      "source": [
        "# GET TWEET LANGUAGE\n",
        "df['tweet_language'] = df['tweet_text'].apply(lambda x: get_sentence_language(str(x)))\n",
        "\n",
        "# FILTER LANGUAGE\n",
        "df = df[df[\"tweet_language\"] == \"en\"]\n",
        "df = df.drop(['tweet_language'], axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIsCKpmEfEsD"
      },
      "source": [
        "df.to_csv('01-post-translate-dataset.csv', index=False)"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}